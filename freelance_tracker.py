import sys
import os
import time
import datetime
import cloudscraper
from bs4 import BeautifulSoup
import requests
from google import genai

# ==========================================
# âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙŠØ±ÙØ±
# ==========================================

BOT_TOKEN = os.getenv("BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¹Ù…ÙŠÙ„
ai_client = None

if GEMINI_API_KEY:
    try:
        ai_client = genai.Client(api_key=GEMINI_API_KEY.strip())
        print("âœ… GenAI Client Connected successfully.")
    except Exception as e:
        print(f"âŒ Client Error: {e}")

# --- Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ---
EXCLUDED_KEYWORDS = [
    "wordpress", "ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³", "ÙˆØ±Ø¯Ø¨Ø±ÙŠØ³", "ÙˆØ±Ø¯ Ø¨Ø±ÙŠØ³", 
    "elementor", "divi", "woocommerce", "ÙˆÙƒÙˆÙ…Ø±Ø³", 
    "shopify", "Ø´ÙˆØ¨ÙŠÙØ§ÙŠ", "Ø³Ù„Ø©", "Ø²Ø¯", "salla", "zid",
    "blogger", "Ø¨Ù„ÙˆØ¬Ø±", "logo", "Ù„ÙˆØ¬Ùˆ", "Ø¨Ø§Ù†Ø±", "Ø´Ø¹Ø§Ø±"
]

WEB_KEYWORDS = [
    "web", "ÙˆÙŠØ¨", "Ù…ÙˆÙ‚Ø¹", "site", "front", "back", 
    "full stack", "full-stack", "php", "laravel", 
    "python", "django", "node", "react", "vue", 
    "api", "sql", "server", "Ø³ÙŠØ±ÙØ±", "Ø§Ø³ØªØ¶Ø§ÙØ©", 
    "Ø±ÙØ¹", "deploy", "javascript", "js", "html", 
    "css", "Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ…", "dashboard", "next.js", 
    "next", "nextjs", "ØµÙØ­Ø© Ù‡Ø¨ÙˆØ·", "landing page"
]

CREATIVE_KEYWORDS = [
    "ØªØµÙ…ÙŠÙ…", "design", "Ø¬Ø±Ø§ÙÙŠÙƒ", "graphic", 
    "Ù…ÙˆÙ†ØªØ§Ø¬", "montage", "edit", "video", 
    "ÙÙŠØ¯ÙŠÙˆ", "Ù…ÙˆØ´Ù†", "ÙÙˆØªÙˆØ´ÙˆØ¨", "photoshop", 
    "premiere", "Ø¨Ø±ÙŠÙ…ÙŠØ±", "Ø±ÙŠÙ„Ø²", "reels"
]

QURAN_KEYWORDS = [
    "Ù‚Ø±Ø¢Ù†", "Ù‚Ø±Ø§Ù†", "Ù‚Ø±Ø¡Ø§Ù†", "quran", 
    "ØªÙ„Ø§ÙˆØ©", "recitation", "Ù…ØµØ­Ù", "ØªØ¬ÙˆÙŠØ¯", 
    "Ø¢ÙŠØ©", "Ø§ÙŠØ©", "Ø§ÙŠÙ‡", "Ø¢ÙŠØ§Øª", "Ø³ÙˆØ±Ø©", 
    "Ø¯ÙŠÙ†ÙŠ", "Ø¯Ø¹ÙˆÙŠ", "Ø¥Ø³Ù„Ø§Ù…ÙŠ", "islamic"
]

URLS = {
    "Mostaql": "https://mostaql.com/projects",
    "Khamsat": "https://khamsat.com/community/requests"
}
POLL_INTERVAL = 60
processed_projects = set()

scraper = cloudscraper.create_scraper(
    browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}
)
scraper.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept-Language': 'ar,en-US;q=0.9,en;q=0.8'
})

def get_full_project_details(link, source):
    try:
        response = scraper.get(link, timeout=15)
        if response.status_code != 200: return None
        soup = BeautifulSoup(response.content, 'html.parser')
        
        description = ""
        if source == "Mostaql":
            desc_elem = soup.select_one('#project-brief-section') or soup.select_one('.project-desc') or soup.select_one('.card-body')
            if desc_elem: description = desc_elem.text.strip()
        elif source == "Khamsat":
            desc_elem = soup.select_one('.article-body') or soup.select_one('.post_content')
            if desc_elem: description = desc_elem.text.strip()
            
        return description[:2500] 
    except Exception as e:
        print(f"   âŒ Detail Fetch Error: {e}")
        return None

def generate_smart_response(title, description):
    """
    ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ 404
    """
    if not ai_client: return "âš ï¸ AI Service Unavailable"
    
    # Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù…Ø£Ø®ÙˆØ°Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ Ø£Ø±Ø³Ù„ØªÙ‡Ø§ (Ø¯Ù‚ÙŠÙ‚Ø© 100%)
    models_to_try = [
        "gemini-2.5-pro",
        "gemini-2.5-flash", 
        "gemini-2.0-flash",       
        "gemini-2.0-flash-lite",  
        "gemini-3-flash-preview"
    ]

    prompt = f"""
    Act as an expert Senior Full Stack Developer and Freelancer.
    
    Project Details:
    - Title: {title}
    - Description: {description}

    Instructions:
    1. Read the project description carefully to understand the client's specific needs (do not rely on the title only).
    2. Write a professional, detailed, and convincing proposal in Arabic. 
       - Do not make it short or generic. 
       - Explain how you will solve their specific problem based on the description.
       - Show enthusiasm and expertise.
    3. At the very end, provide a realistic estimation for the Cost (in USD) and Duration (in Days) based on the scope of work described.

    Required Output Format:
    [The Proposal Text in Arabic]
    Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€
    ğŸ’¡ *Ø§Ù„ØªÙ‚Ø¯ÙŠØ±:* [Price] | [Duration]
    """
    
    for model_name in models_to_try:
        try:
            # print(f"   ğŸ”„ Trying: {model_name}...") # (Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„ØªØªØ¨Ø¹)
            response = ai_client.models.generate_content(
                model=model_name, 
                contents=prompt
            )
            print(f"   âœ… Success using: {model_name}")
            return response.text
        except Exception as e:
            # Ù„Ùˆ ÙØ´Ù„ Ù†Ø¬Ø±Ø¨ Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡ Ø¨ØµÙ…Øª
            continue

    return "ØªØ¹Ø°Ø± ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©."

def send_telegram_message(title, link, source, category):
    if not BOT_TOKEN or not CHAT_ID: 
        print("ğŸ›‘ Error: Missing Telegram Tokens")
        return

    description = get_full_project_details(link, source)
    if not description: description = title 

    ai_text = generate_smart_response(title, description)

    # 1. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ø¶Ù…Ø§Ù† ÙˆØµÙˆÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© (Ø³Ù†Ø§Ù‚ÙˆÙ… Ø¨Ø¥Ø±Ø¬Ø§Ø¹Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¢Ù…Ù†Ø©)
    # Ù„Ø§Ø­Ø¸ Ø£Ù†Ù†ÙŠ Ø­Ø°ÙØª "parse_mode": "Markdown" Ù…Ù† Ø§Ù„Ø£Ø³ÙÙ„
    msg = f"""ğŸ”” Ù…Ø´Ø±ÙˆØ¹ {category} Ø¬Ø¯ÙŠØ¯ ({source})

ğŸ“ {title}

ğŸ”— {link}

Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€Ù€
{ai_text}
"""
    
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    # Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ø²Ø§Ù„Ø© parse_mode Ù…Ø¤Ù‚ØªØ§Ù‹
    payload = {"chat_id": CHAT_ID, "text": msg} 
    
    try:
        response = requests.post(url, data=payload)
        
        # 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù…Ù† Ø±Ø¯ ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        if response.status_code == 200:
            print(f"   âœ… Notification Sent Successfully: {title}")
        else:
            # Ù‡Ù†Ø§ Ø³ÙŠØ¸Ù‡Ø± Ù„Ùƒ Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¥Ø°Ø§ Ù„Ù… ØªØµÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
            print(f"   âš ï¸ Telegram Error: {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"   âŒ Network Error: {e}")

def check_project_filter(title):
    text = title.lower()
    if any(w in text for w in EXCLUDED_KEYWORDS): return None
    if any(w in text for w in WEB_KEYWORDS): return "ÙˆÙŠØ¨ ğŸ’»"
    is_creative = any(w in text for w in CREATIVE_KEYWORDS)
    is_quran = any(w in text for w in QURAN_KEYWORDS)
    if is_creative and is_quran: return "Ù‚Ø±Ø¢Ù† ğŸ•Œ"
    return None

def scrape_site(source_name, url, is_first_run=False):
    print(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] Checking {source_name}...", end=" ")
    try:
        response = scraper.get(url, timeout=30)
        if response.status_code != 200:
            print(f"HTTP Error: {response.status_code}")
            return

        soup = BeautifulSoup(response.content, 'html.parser')
        projects = []

        if source_name == "Mostaql":
            rows = soup.select('tr.project-row h2 a, .project-title a, h2 a')
            for t_elem in rows:
                if t_elem:
                    title = t_elem.text.strip()
                    href = t_elem['href']
                    link = "https://mostaql.com" + href if not href.startswith("http") else href
                    projects.append((title, link))
        
        elif source_name == "Khamsat":
            links = soup.find_all('a', href=True)
            for t in links:
                href = t['href']
                if "/community/requests/" in href and any(c.isdigit() for c in href):
                    title = t.text.strip()
                    if len(title) < 5: continue
                    link = "https://khamsat.com" + href if not href.startswith("http") else href
                    if not any(p[1] == link for p in projects): 
                        projects.append((title, link))

        print(f"-> Found {len(projects)}")

        for title, link in projects:
            if link in processed_projects: continue
            
            if is_first_run:
                processed_projects.add(link)
                continue
            
            cat = check_project_filter(title)
            if cat:
                print(f"   ğŸ”¥ Match: {title}")
                send_telegram_message(title, link, source_name, cat)
            
            processed_projects.add(link)
            
    except Exception as e:
        print(f"\nâŒ Scraping Error: {e}")

def main():
    print("--- ğŸ¤– Freelance Bot (Smart Edition V3) ---")
    
    if not BOT_TOKEN or not CHAT_ID:
        print("ğŸ›‘ Missing Tokens!")
        return

    print("1. Initializing & caching existing projects...")
    for src, url in URLS.items(): scrape_site(src, url, is_first_run=True)
    
    print(f"\nâœ… Ready! Watching for new projects...")
    
    while True:
        try:
            for src, url in URLS.items(): scrape_site(src, url, is_first_run=False)
            time.sleep(POLL_INTERVAL)
        except Exception as e:
            print(f"Main Loop Error: {e}")
            time.sleep(POLL_INTERVAL)

if __name__ == "__main__":
    main()