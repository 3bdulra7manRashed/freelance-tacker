import sys
import os
import time
import datetime
import cloudscraper
from bs4 import BeautifulSoup
import requests
from google import genai

# ==========================================
# ‚öôÔ∏è ÿ•ÿπÿØÿßÿØÿßÿ™ ÿßŸÑÿ≥Ÿäÿ±ŸÅÿ±
# ==========================================

BOT_TOKEN = os.getenv("BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ÿ•ÿπÿØÿßÿØ ÿßŸÑÿπŸÖŸäŸÑ
ai_client = None

if GEMINI_API_KEY:
    try:
        ai_client = genai.Client(api_key=GEMINI_API_KEY.strip())
        print("‚úÖ GenAI Client Connected successfully.")
    except Exception as e:
        print(f"‚ùå Client Error: {e}")

# --- ÿßŸÑŸÉŸÑŸÖÿßÿ™ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠Ÿäÿ© ---
EXCLUDED_KEYWORDS = [
    "wordpress", "ŸàŸàÿ±ÿØÿ®ÿ±Ÿäÿ≥", "Ÿàÿ±ÿØÿ®ÿ±Ÿäÿ≥", "Ÿàÿ±ÿØ ÿ®ÿ±Ÿäÿ≥", 
    "elementor", "divi", "woocommerce", "ŸàŸÉŸàŸÖÿ±ÿ≥", 
    "shopify", "ÿ¥Ÿàÿ®ŸäŸÅÿßŸä", "ÿ≥ŸÑÿ©", "ÿ≤ÿØ", "salla", "zid",
    "blogger", "ÿ®ŸÑŸàÿ¨ÿ±", "logo", "ŸÑŸàÿ¨Ÿà", "ÿ®ÿßŸÜÿ±", "ÿ¥ÿπÿßÿ±"
]

WEB_KEYWORDS = [
    "web", "ŸàŸäÿ®", "ŸÖŸàŸÇÿπ", "site", "front", "back", 
    "full stack", "full-stack", "php", "laravel", 
    "python", "django", "node", "react", "vue", 
    "api", "sql", "server", "ÿ≥Ÿäÿ±ŸÅÿ±", "ÿßÿ≥ÿ™ÿ∂ÿßŸÅÿ©", 
    "ÿ±ŸÅÿπ", "deploy", "javascript", "js", "html", 
    "css", "ŸÑŸàÿ≠ÿ© ÿ™ÿ≠ŸÉŸÖ", "dashboard", "next.js", 
    "next", "nextjs", "ÿµŸÅÿ≠ÿ© Ÿáÿ®Ÿàÿ∑", "landing page"
]

CREATIVE_KEYWORDS = [
    "ÿ™ÿµŸÖŸäŸÖ", "design", "ÿ¨ÿ±ÿßŸÅŸäŸÉ", "graphic", 
    "ŸÖŸàŸÜÿ™ÿßÿ¨", "montage", "edit", "video", 
    "ŸÅŸäÿØŸäŸà", "ŸÖŸàÿ¥ŸÜ", "ŸÅŸàÿ™Ÿàÿ¥Ÿàÿ®", "photoshop", 
    "premiere", "ÿ®ÿ±ŸäŸÖŸäÿ±", "ÿ±ŸäŸÑÿ≤", "reels"
]

QURAN_KEYWORDS = [
    "ŸÇÿ±ÿ¢ŸÜ", "ŸÇÿ±ÿßŸÜ", "ŸÇÿ±ÿ°ÿßŸÜ", "quran", 
    "ÿ™ŸÑÿßŸàÿ©", "recitation", "ŸÖÿµÿ≠ŸÅ", "ÿ™ÿ¨ŸàŸäÿØ", 
    "ÿ¢Ÿäÿ©", "ÿßŸäÿ©", "ÿßŸäŸá", "ÿ¢Ÿäÿßÿ™", "ÿ≥Ÿàÿ±ÿ©", 
    "ÿØŸäŸÜŸä", "ÿØÿπŸàŸä", "ÿ•ÿ≥ŸÑÿßŸÖŸä", "islamic"
]

URLS = {
    "Mostaql": "https://mostaql.com/projects",
    "Khamsat": "https://khamsat.com/community/requests"
}
POLL_INTERVAL = 60
processed_projects = set()

scraper = cloudscraper.create_scraper(
    browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}
)
scraper.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept-Language': 'ar,en-US;q=0.9,en;q=0.8'
})

def get_full_project_details(link, source):
    try:
        response = scraper.get(link, timeout=15)
        if response.status_code != 200: return None
        soup = BeautifulSoup(response.content, 'html.parser')
        
        description = ""
        if source == "Mostaql":
            desc_elem = soup.select_one('#project-brief-section') or soup.select_one('.project-desc') or soup.select_one('.card-body')
            if desc_elem: description = desc_elem.text.strip()
        elif source == "Khamsat":
            desc_elem = soup.select_one('.article-body') or soup.select_one('.post_content')
            if desc_elem: description = desc_elem.text.strip()
            
        return description[:2500] 
    except Exception as e:
        print(f"   ‚ùå Detail Fetch Error: {e}")
        return None

def generate_smart_response(title, description):
    """
    Ÿäÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑŸÖŸàÿØŸäŸÑÿßÿ™ ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ÿ≠ÿ≥ÿßÿ®ŸÉ ÿ®ÿßŸÑÿ∂ÿ®ÿ∑ ŸÑÿ™ÿ¨ŸÜÿ® ÿÆÿ∑ÿ£ 404
    """
    if not ai_client: return "‚ö†Ô∏è AI Service Unavailable"
    
    # Ÿáÿ∞Ÿá ÿßŸÑŸÇÿßÿ¶ŸÖÿ© ŸÖÿ£ÿÆŸàÿ∞ÿ© ŸÖŸÜ ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ™Ÿä ÿ£ÿ±ÿ≥ŸÑÿ™Ÿáÿß (ÿØŸÇŸäŸÇÿ© 100%)
    models_to_try = [
        "gemini-2.5-pro",
        "gemini-2.5-flash", 
        "gemini-2.0-flash",       
        "gemini-2.0-flash-lite",  
        "gemini-3-flash-preview"
    ]

    prompt = f"""
You are an expert **Senior Full Stack Developer & Professional Freelancer**.

Project Information:
- Title: {title}
- Description: {description}

Your Task:
1. Read and analyze the project description carefully. Focus on the actual needs, not just the title.
2. Write a **professional, convincing proposal in Arabic only**.
3. The proposal must:
   - Show confidence, experience, and understanding of the client's needs.
   - Explain briefly how you will execute the project step-by-step.
   - Suggest suitable technologies (Laravel / Next.js / APIs / MySQL ... depending on context).
   - Must NOT contain price or duration inside the main proposal text.
4. After the proposal, provide a **realistic estimation (in USD and Days)** in a separate line.

Output Format (VERY IMPORTANT):
Write the proposal text only in **Arabic**.

Then add at the end exactly in this format:

ŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄŸÄ
üí° *ÿßŸÑÿ™ŸÇÿØŸäÿ±:* [Price in USD] | [Duration in Days]
"""

    
    for model_name in models_to_try:
        try:
            # print(f"   üîÑ Trying: {model_name}...") # (ÿßÿÆÿ™Ÿäÿßÿ±Ÿä ŸÑŸÑÿ™ÿ™ÿ®ÿπ)
            response = ai_client.models.generate_content(
                model=model_name, 
                contents=prompt
            )
            print(f"   ‚úÖ Success using: {model_name}")
            return response.text
        except Exception as e:
            # ŸÑŸà ŸÅÿ¥ŸÑ ŸÜÿ¨ÿ±ÿ® ÿßŸÑŸÑŸä ÿ®ÿπÿØŸá ÿ®ÿµŸÖÿ™
            continue

    return "ÿ™ÿπÿ∞ÿ± ÿ™ŸàŸÑŸäÿØ ÿßŸÑÿ±ÿØ ŸÖŸÜ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖŸàÿØŸäŸÑÿßÿ™ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ©."

def send_telegram_message(title, link, source, category):
    if not BOT_TOKEN or not CHAT_ID: return

    # -------------------------------------------------------
    # 1Ô∏è‚É£ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ£ŸàŸÑŸâ: ÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ (ÿ™ÿµŸÑ ŸÅŸàÿ±ÿßŸã)
    # -------------------------------------------------------
    print(f"   üöÄ Sending Project Notification: {title}")
    
    msg1 = f"""üîî ŸÖÿ¥ÿ±Ÿàÿπ {category} ÿ¨ÿØŸäÿØ ({source})

üìù {title}

üîó {link}"""

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    
    # ŸÜÿ±ÿ≥ŸÑ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ£ŸàŸÑŸâ (ÿ®ÿØŸàŸÜ Markdown ŸÑÿ™ÿ¨ŸÜÿ® ÿßŸÑÿ£ÿÆÿ∑ÿßÿ° ŸÅŸä ÿßŸÑÿπŸÜÿßŸàŸäŸÜ ÿßŸÑÿ∫ÿ±Ÿäÿ®ÿ©)
    try:
        r1 = requests.post(url, data={"chat_id": CHAT_ID, "text": msg1})
        if r1.status_code != 200:
            print(f"   ‚ö†Ô∏è Project Msg Failed: {r1.text}")
    except Exception as e:
        print(f"   ‚ùå Network Error (Msg1): {e}")

    # -------------------------------------------------------
    # 2Ô∏è‚É£ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ´ÿßŸÜŸäÿ©: ÿßŸÑÿπÿ±ÿ∂ ÿßŸÑÿ∞ŸÉŸä (ÿ™ÿµŸÑ ÿ®ÿπÿØ ÿ´ŸàÿßŸÜŸç)
    # -------------------------------------------------------
    
    # ŸÜÿ¨ŸÑÿ® ÿßŸÑŸàÿµŸÅ ÿßŸÑÿ¢ŸÜ ÿπÿ¥ÿßŸÜ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä
    description = get_full_project_details(link, source)
    if not description: description = title 

    print(f"   ü§ñ Generating Proposal...")
    ai_text = generate_smart_response(title, description)

    # ŸÖŸÇÿµ ÿßŸÑÿ£ŸÖÿßŸÜ ŸÑŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ´ÿßŸÜŸäÿ© (ŸÑŸà ÿßŸÑÿπÿ±ÿ∂ ÿ∑ŸàŸäŸÑ ÿ¨ÿØÿßŸã)
    if len(ai_text) > 4000:
        ai_text = ai_text[:4000] + "\n...(ÿ™ŸÖ ŸÇÿµ ÿßŸÑÿπÿ±ÿ∂ ŸÑÿ∑ŸàŸÑŸá ÿßŸÑÿ≤ÿßÿ¶ÿØ)"

    try:
        r2 = requests.post(url, data={"chat_id": CHAT_ID, "text": ai_text})
        if r2.status_code == 200:
            print(f"   ‚úÖ Proposal Sent Successfully!")
        else:
            print(f"   ‚ö†Ô∏è Proposal Msg Failed: {r2.text}")
            
    except Exception as e:
        print(f"   ‚ùå Network Error (Msg2): {e}")

def check_project_filter(title):
    text = title.lower()
    if any(w in text for w in EXCLUDED_KEYWORDS): return None
    if any(w in text for w in WEB_KEYWORDS): return "ŸàŸäÿ® üíª"
    is_creative = any(w in text for w in CREATIVE_KEYWORDS)
    is_quran = any(w in text for w in QURAN_KEYWORDS)
    if is_creative and is_quran: return "ŸÇÿ±ÿ¢ŸÜ üïå"
    return None

def scrape_site(source_name, url, is_first_run=False):
    print(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] Checking {source_name}...", end=" ")
    try:
        response = scraper.get(url, timeout=30)
        if response.status_code != 200:
            print(f"HTTP Error: {response.status_code}")
            return

        soup = BeautifulSoup(response.content, 'html.parser')
        projects = []

        if source_name == "Mostaql":
            rows = soup.select('tr.project-row h2 a, .project-title a, h2 a')
            for t_elem in rows:
                if t_elem:
                    title = t_elem.text.strip()
                    href = t_elem['href']
                    link = "https://mostaql.com" + href if not href.startswith("http") else href
                    projects.append((title, link))
        
        elif source_name == "Khamsat":
            links = soup.find_all('a', href=True)
            for t in links:
                href = t['href']
                if "/community/requests/" in href and any(c.isdigit() for c in href):
                    title = t.text.strip()
                    if len(title) < 5: continue
                    link = "https://khamsat.com" + href if not href.startswith("http") else href
                    if not any(p[1] == link for p in projects): 
                        projects.append((title, link))

        print(f"-> Found {len(projects)}")

        for title, link in projects:
            if link in processed_projects: continue
            
            if is_first_run:
                processed_projects.add(link)
                continue
            
            cat = check_project_filter(title)
            if cat:
                print(f"   üî• Match: {title}")
                send_telegram_message(title, link, source_name, cat)
            
            processed_projects.add(link)
            
    except Exception as e:
        print(f"\n‚ùå Scraping Error: {e}")

def main():
    print("--- ü§ñ Freelance Bot (Smart Edition V3) ---")
    
    if not BOT_TOKEN or not CHAT_ID:
        print("üõë Missing Tokens!")
        return

    print("1. Initializing & caching existing projects...")
    for src, url in URLS.items(): scrape_site(src, url, is_first_run=True)
    
    print(f"\n‚úÖ Ready! Watching for new projects...")
    
    while True:
        try:
            for src, url in URLS.items(): scrape_site(src, url, is_first_run=False)
            time.sleep(POLL_INTERVAL)
        except Exception as e:
            print(f"Main Loop Error: {e}")
            time.sleep(POLL_INTERVAL)

if __name__ == "__main__":
    main()