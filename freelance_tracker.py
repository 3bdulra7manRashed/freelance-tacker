import sys
import os
import time
import datetime
import importlib
import cloudscraper
from bs4 import BeautifulSoup
import requests

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù† (Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± Ù…Ø¨Ø§Ø´Ø±Ø©) ---
# Ø§Ù„ÙƒÙˆØ¯ Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Coolify
BOT_TOKEN = os.getenv("BOT_TOKEN")
CHAT_ID = os.getenv("CHAT_ID")

URLS = {
    "Mostaql": "https://mostaql.com/projects",
    "Khamsat": "https://khamsat.com/community/requests"
}

POLL_INTERVAL = 120
processed_projects = set()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØµÙØ­ Ø§Ù„ÙˆÙ‡Ù…ÙŠ Ù„ØªØ®Ø·ÙŠ Ø§Ù„Ø­Ù…Ø§ÙŠØ©
scraper = cloudscraper.create_scraper(
    browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}
)

# --- 2. Ø§Ù„ÙÙ„Ø§ØªØ± ---
EXCLUDED_KEYWORDS = ["wordpress", "ÙˆÙˆØ±Ø¯Ø¨Ø±ÙŠØ³", "ÙˆØ±Ø¯Ø¨Ø±ÙŠØ³", "ÙˆØ±Ø¯ Ø¨Ø±ÙŠØ³", "elementor", "divi", "woocommerce", "ÙˆÙƒÙˆÙ…Ø±Ø³", "shopify", "Ø´ÙˆØ¨ÙŠÙØ§ÙŠ", "Ø³Ù„Ø©", "Ø²Ø¯", "salla", "zid"]
WEB_KEYWORDS = ["web", "ÙˆÙŠØ¨", "Ù…ÙˆÙ‚Ø¹", "site", "front", "back", "full stack", "full-stack", "php", "laravel", "python", "django", "node", "react", "vue", "api", "sql", "server", "Ø³ÙŠØ±ÙØ±", "Ø§Ø³ØªØ¶Ø§ÙØ©", "Ø±ÙØ¹", "deploy", "javascript", "js", "html", "css","Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ…","dashboard","next.js","next","nextjs"]
CREATIVE_KEYWORDS = ["ØªØµÙ…ÙŠÙ…", "design", "Ø¬Ø±Ø§ÙÙŠÙƒ", "graphic", "Ø´Ø¹Ø§Ø±", "logo", "Ù…ÙˆÙ†ØªØ§Ø¬", "montage", "edit", "video", "ÙÙŠØ¯ÙŠÙˆ", "Ù…ÙˆØ´Ù†", "ÙÙˆØªÙˆØ´ÙˆØ¨", "photoshop", "premiere", "Ø¨Ø±ÙŠÙ…ÙŠØ±", "Ø±ÙŠÙ„Ø²", "reels"]
QURAN_KEYWORDS = ["Ù‚Ø±Ø¢Ù†","Ù‚Ø±Ø§Ù†","Ù‚Ø±Ø¡Ø§Ù†", "quran", "ØªÙ„Ø§ÙˆØ©", "recitation", "Ù…ØµØ­Ù", "ØªØ¬ÙˆÙŠØ¯", "Ø¢ÙŠØ©","Ø§ÙŠØ©","Ø§ÙŠÙ‡", "Ø¢ÙŠØ§Øª", "Ø³ÙˆØ±Ø©", "Ø¯ÙŠÙ†ÙŠ", "Ø¯Ø¹ÙˆÙŠ", "Ø¥Ø³Ù„Ø§Ù…ÙŠ", "islamic"]

def send_telegram_message(title, link, source, category):
    if not BOT_TOKEN or not CHAT_ID:
        print("âŒ Error: BOT_TOKEN or CHAT_ID is missing from Environment Variables!")
        return
    
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    msg = f"ğŸ”” **Ø·Ù„Ø¨ {category} Ø¬Ø¯ÙŠØ¯ ({source})**\n\nğŸ“ {title}\n\nğŸ”— {link}"
    payload = {"chat_id": CHAT_ID, "text": msg, "parse_mode": "Markdown"}
    try:
        requests.post(url, data=payload)
    except Exception as e:
        print(f"Error sending Telegram: {e}")

def check_project_filter(title):
    full_text = title.lower()
    if any(w in full_text for w in EXCLUDED_KEYWORDS): return None
    if any(w in full_text for w in WEB_KEYWORDS): return "ÙˆÙŠØ¨ ğŸ’»"
    is_creative = any(w in full_text for w in CREATIVE_KEYWORDS)
    is_quran = any(w in full_text for w in QURAN_KEYWORDS)
    if is_creative and is_quran: return "Ù‚Ø±Ø¢Ù† ğŸ•Œ"
    return None

def scrape_site(source_name, url, is_first_run=False):
    print(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] Scraping {source_name}...")
    try:
        response = scraper.get(url, timeout=30)
        if response.status_code != 200: return
        soup = BeautifulSoup(response.content, 'html.parser')
        projects = []

        if source_name == "Mostaql":
            rows = soup.select('tr.project-row')
            for row in rows:
                title_elem = row.select_one('h2.mrg--bt-reset a')
                if title_elem:
                    link = title_elem['href']
                    full_link = "https://mostaql.com" + link if not link.startswith("http") else link
                    projects.append((title_elem.text.strip(), full_link))
        
        elif source_name == "Khamsat":
            all_links = soup.find_all('a', href=True)
            for t in all_links:
                href = t['href']
                if "/community/requests/" in href and any(char.isdigit() for char in href):
                    title = t.text.strip()
                    if len(title) < 5: continue
                    full_link = "https://khamsat.com" + href if not href.startswith("http") else href
                    if not any(p[1] == full_link for p in projects):
                        projects.append((title, full_link))

        for title, link in projects:
            if link in processed_projects: continue
            if is_first_run:
                processed_projects.add(link)
                continue
            category = check_project_filter(title)
            if category:
                send_telegram_message(title, link, source_name, category)
                print(f"  âœ… Match Found: {title}")
            processed_projects.add(link)
    except Exception as e:
        print(f"  âŒ Error: {e}")

def main():
    print("--- Freelance Bot (Coolify Edition) Started ---")
    if not BOT_TOKEN or not CHAT_ID:
        print("ğŸ›‘ Critical Error: Variables BOT_TOKEN or CHAT_ID not set!")
        return

    for source, url in URLS.items():
        scrape_site(source, url, is_first_run=True)
        time.sleep(2)
    
    print(f"Initialization Done. Tracking {len(processed_projects)} items.\n")
    while True:
        for source, url in URLS.items():
            scrape_site(source, url, is_first_run=False)
            time.sleep(3)
        time.sleep(POLL_INTERVAL)

if __name__ == "__main__":
    main()